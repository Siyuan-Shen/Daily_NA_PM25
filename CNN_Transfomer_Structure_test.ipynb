{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14733dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Model_Structure_pkg.CNN_Transformer_Model.model.CNN_transformer' from '/Volumes/rvmartin2/Active/s.siyuan/Projects/Daily_PM25_DL_2024/code/Training_Validation_Estimation/PM25/v0.3.0/Model_Structure_pkg/CNN_Transformer_Model/model/CNN_transformer.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import Model_Structure_pkg.CNN_Transformer_Model.model.CNN_transformer as CNN_transformer\n",
    "import Model_Structure_pkg.CNN_Transformer_Model.model.decoder as decoder\n",
    "import Model_Structure_pkg.CNN_Transformer_Model.model.encoder as encoder\n",
    "\n",
    "# Reload all submodules in correct dependency order\n",
    "importlib.reload(decoder)\n",
    "importlib.reload(encoder)\n",
    "importlib.reload(CNN_transformer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342c40ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer initialized with parameters:\n",
      "CNN Input Dimension: 4, Transformer Input Dimension: 517, Target Dimension: 1, d_model: 64, n_head: 8, ffn_hidden: 256, num_layers: 2, max_len: 40, drop_prob: 0.1\n",
      "size of target_data: torch.Size([16, 32, 1])\n",
      "Output shape: torch.Size([16, 32, 1])\n",
      "Output shape matches target shape.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import Model_Structure_pkg.Transformer_Model\n",
    "import Model_Structure_pkg.CNN_Transformer_Model.model.decoder as decoder\n",
    "import Model_Structure_pkg.CNN_Transformer_Model.model.encoder as encoder\n",
    "import Model_Structure_pkg.CNN_Transformer_Model.model.CNN_transformer as CNN_Transformer\n",
    "\n",
    "# Reload all submodules in correct dependency order\n",
    "importlib.reload(decoder)\n",
    "importlib.reload(encoder)\n",
    "importlib.reload(CNN_Transformer)\n",
    "\n",
    "## Prepare some datasets as targets and inputs for the Transformer model\n",
    "CNN_input_dim = 4  # Number of input features (e.g., channels)\n",
    "input_dim = 5  # Number of input features (e.g., channels)\n",
    "trg_dim = 1    # Number of target features (e.g., PM2.5)\n",
    "d_model = 64   # Dimension of the model (hidden size)\n",
    "n_head = 8     # Number of attention heads\n",
    "ffn_hidden = 256  # Dimension of the feed-forward network hidden layer\n",
    "num_layers = 2  # Number of encoder/decoder layers\n",
    "max_len = 40  # Maximum length of the input sequence\n",
    "drop_prob = 0.1  # Dropout probability\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transformer_model = CNN_Transformer.CNN_Transformer(CNN_input_dim, input_dim,trg_dim, d_model, n_head, ffn_hidden, num_layers, max_len, drop_prob,device)\n",
    "\n",
    "#prepare some input daata and target data batchs\n",
    "batch_size = 16  # Number of samples in a batch\n",
    "seq_length = 32  # Length of each input sequence\n",
    "CNN_input_data = torch.randn(batch_size, seq_length, CNN_input_dim,11,11).to(device)  # Input data shape: (batch_size, seq_length, input_dim)\n",
    "input_data = torch.randn(batch_size, seq_length, input_dim).to(device)  # Input data shape: (batch_size, seq_length, input_dim)\n",
    "input_data = input_data + torch.Tensor(np.arange(seq_length)[:, np.newaxis]).to(device)  # Add a positional encoding\n",
    "input_sum = torch.sum(input_data, dim=-1, keepdim=True)  # Sum over the last dimension\n",
    "\n",
    "#Create a target_data tensor for learning, suitable for transformer\n",
    "target_data = torch.Tensor(torch.square(input_sum)+0.32*input_sum+0.02).to(device)  # Target data shape: (batch_size, seq_length, trg_dim)\n",
    "\n",
    "print('size of target_data:', target_data.size())\n",
    "## select some random elements in target_data to nan values\n",
    "nan_indices = np.random.choice(seq_length, size=int(seq_length * 0.1), replace=False)  # 10% of the target data will be NaN\n",
    "target_data[:, nan_indices, :] = float('nan')  # Set selected indices to NaN\n",
    "\n",
    "# Forward pass through the Transformer model\n",
    "output = transformer_model(CNN_input_data, input_data, target_data)\n",
    "# Output shape: (batch_size, seq_length, trg_dim)\n",
    "print(\"Output shape:\", output.shape)\n",
    "# Check if the output shape matches the expected target shape\n",
    "if output.shape == target_data.shape:\n",
    "    print(\"Output shape matches target shape.\")\n",
    "else:\n",
    "    print(\"Output shape does not match target shape.\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da264b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 126517384.0\n",
      "Epoch [1/17], Loss: 126517384.0000, R2: -1.2093\n",
      "Epoch: 1 Loss: 126488896.0\n",
      "Epoch [2/17], Loss: 126488896.0000, R2: -1.2088\n",
      "Epoch: 2 Loss: 126471688.0\n",
      "Epoch [3/17], Loss: 126471688.0000, R2: -1.2085\n",
      "Epoch: 3 Loss: 126461840.0\n",
      "Epoch [4/17], Loss: 126461840.0000, R2: -1.2083\n",
      "Epoch: 4 Loss: 126455648.0\n",
      "Epoch [5/17], Loss: 126455648.0000, R2: -1.2082\n",
      "Epoch: 5 Loss: 126451936.0\n",
      "Epoch [6/17], Loss: 126451936.0000, R2: -1.2081\n",
      "Epoch: 6 Loss: 126449968.0\n",
      "Epoch [7/17], Loss: 126449968.0000, R2: -1.2081\n",
      "Epoch: 7 Loss: 126448696.0\n",
      "Epoch [8/17], Loss: 126448696.0000, R2: -1.2081\n",
      "Epoch: 8 Loss: 126447392.0\n",
      "Epoch [9/17], Loss: 126447392.0000, R2: -1.2081\n",
      "Epoch: 9 Loss: 126446352.0\n",
      "Epoch [10/17], Loss: 126446352.0000, R2: -1.2080\n",
      "Epoch: 10 Loss: 126445288.0\n",
      "Epoch [11/17], Loss: 126445288.0000, R2: -1.2080\n",
      "Epoch: 11 Loss: 126444144.0\n",
      "Epoch [12/17], Loss: 126444144.0000, R2: -1.2080\n",
      "Epoch: 12 Loss: 126442936.0\n",
      "Epoch [13/17], Loss: 126442936.0000, R2: -1.2080\n",
      "Epoch: 13 Loss: 126441816.0\n",
      "Epoch [14/17], Loss: 126441816.0000, R2: -1.2080\n",
      "Epoch: 14 Loss: 126440640.0\n",
      "Epoch [15/17], Loss: 126440640.0000, R2: -1.2079\n",
      "Epoch: 15 Loss: 126439488.0\n",
      "Epoch [16/17], Loss: 126439488.0000, R2: -1.2079\n",
      "Epoch: 16 Loss: 126438216.0\n",
      "Epoch [17/17], Loss: 126438216.0000, R2: -1.2079\n",
      "Test R2 Score: 0.0004\n",
      "Test output shape: torch.Size([16, 32, 1])\n",
      "Test output shape matches target shape.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Try to train a transformer model with the input and target data\n",
    "criterion = nn.MSELoss()  # Mean Squared Error Loss\n",
    "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=0.001)  # Adam\n",
    "# Training loop\n",
    "num_epochs = 17  # Number of epochs for training\n",
    "def r2_score(y_true, y_pred, mask):\n",
    "    \"\"\"\n",
    "    Computes the R^2 score.\n",
    "    \"\"\"\n",
    "    y_true = y_true[mask]\n",
    "    y_pred = y_pred[mask]\n",
    "    ss_total = ((y_true - y_true.mean()) ** 2).sum()\n",
    "    ss_residual = ((y_true - y_pred) ** 2).sum()\n",
    "    return 1 - (ss_residual / ss_total)\n",
    "\n",
    "def masked_mse_loss(predictions, targets, mask):\n",
    "    \"\"\"\n",
    "    Computes the mean squared error loss with a mask.\n",
    "    \n",
    "    predictions: (B, T, D)\n",
    "    targets:     (B, T, D)\n",
    "    mask:        (B, T) or (B, T, 1) with 1 for valid, 0 for invalid\n",
    "    \"\"\"\n",
    "    # Ensure mask is broadcastable\n",
    "    if mask.dim() == 2:\n",
    "        mask = mask.unsqueeze(-1)\n",
    "    mask = mask.expand_as(targets).float()  # (B, T, D)\n",
    "    squared_error = (predictions - targets) ** 2\n",
    "    #print('squared_error:', squared_error, 'mask:', mask)  # Debugging shapes\n",
    "    #print('predictions:', predictions)\n",
    "    masked_loss = squared_error * mask\n",
    "    #print('squared_error:', squared_error[0,:,:],'mask:', mask[0,:,:], 'masked_loss:', masked_loss[0,:,:])\n",
    "    loss = masked_loss.sum() / mask.sum().clamp(min=1e-8)  # avoid divide by zero\n",
    "    return loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    transformer_model.train()  # Set the model to training mode\n",
    "    optimizer.zero_grad()  # Zero the gradients\n",
    "    output = transformer_model(CNN_input_data,input_data, target_data)  # Forward pass\n",
    "    #print('output:', output)\n",
    "    \n",
    "    mask = ~torch.isnan(target_data)  # Create a mask for valid target data (not NaN)\n",
    "    filled_target_data = torch.nan_to_num(target_data, nan=0.0)  # Fill NaN values in target data with 0.0\n",
    "    loss = masked_mse_loss(output, filled_target_data, mask)  # Compute the loss\n",
    "    \n",
    "    print('Epoch:', epoch, 'Loss:', loss.item())\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update the model parameters\n",
    "    # Calculate the R2 of output and target\n",
    "    r2 = r2_score(filled_target_data.detach().cpu().numpy(), output.detach().cpu().numpy(), mask.detach().cpu().numpy())\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, R2: {r2:.4f}\")  # Print the loss for each epoch\n",
    "\n",
    "# Save the trained model\n",
    "#torch.save(transformer_model.state_dict(), 'transformer_model.pth') \n",
    "# Load the trained model\n",
    "#transformer_model.load_state_dict(torch.load('transformer_model.pth'))\n",
    "transformer_model.eval()  # Set the model to evaluation mode\n",
    "# Test the model with a new input\n",
    "\n",
    "cnn_test_input = torch.randn(batch_size, seq_length, CNN_input_dim,11,11).to(device)  # New CNN input data for testing\n",
    "test_input = torch.randn(batch_size, seq_length, input_dim).to(device)  # New input data for testing\n",
    "test_target = target_data = torch.sum(torch.square(test_input)+0.32*test_input+0.02, dim=-1).to(device).unsqueeze(-1)  # Target data shape: (batch_size, seq_length, trg_dim)\n",
    "test_output = transformer_model(cnn_test_input, test_input)  # Forward pass with the test input\n",
    "mask = ~torch.isnan(test_output)  # Create a mask for valid test output (not NaN)\n",
    "r2 = r2_score(test_target.detach().cpu().numpy(), test_output.detach().cpu().numpy(), mask.detach().cpu().numpy())\n",
    "print(f\"Test R2 Score: {r2:.4f}\")  # Print the R2 score for the test output\n",
    "\n",
    "print(\"Test output shape:\", test_output.shape)  # Output shape should be (batch_size, seq_length, trg_dim)\n",
    "# Check if the test output shape matches the expected target shape\n",
    "if test_output.shape == target_data.shape:\n",
    "    print(\"Test output shape matches target shape.\")\n",
    "else:\n",
    "    print(\"Test output shape does not match target shape.\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
